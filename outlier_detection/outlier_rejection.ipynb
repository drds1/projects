{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function aims to apply sigma-clipping to reject outlying data points in time-series data. The model iterativelty fits a smooth polynomial function (with the order as an input parameter) and rejects outliers beyond n-standard deviations of the fit (n is the second input parameter). The iterations end when no further poins are rejected or after a maximum of 100 is reached (the process should never take this long and a flag will raise if this occurs).\n",
    "\n",
    "First import requried modiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.optimize as mcf\n",
    "import scipy.signal as ssig\n",
    "import matplotlib.gridspec as gridspec\n",
    "from statsmodels import robust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the outlier rejection function. \n",
    "\n",
    "\n",
    "Arguments are as follows...\n",
    "\n",
    "INPUTS: \n",
    "data_y_in, data_x_in --> 1D array containing the values of the time-series.\n",
    "\n",
    "\n",
    "\n",
    "OPTIONAL INPUTS:\n",
    "\n",
    "data_x_in            --> 1D arrays containing the time axis of the time-series (if no data_x_in entered, code assumes evenly spaced data).\n",
    "\n",
    "\n",
    "sd_check             --> The number of standard deviations from the fitted model (see fname) to consider a point outliying.\n",
    "\n",
    "fname                --> The type of smooth model to fit to the time series prior to rejection (linear, polynomial, running mean, running median).\n",
    "\n",
    "filter_size          --> The size of the window to use for running mean and median computation (for running mean and median functions only).\n",
    "\n",
    "max_iteration        --> Defines the stopping point for the sigma clipping (either when no further points are rejected or when max_iteration is reached).\n",
    "\n",
    "\n",
    "diagnostic_figure    --> The name of an output figure showing the time-series with the outliers flagged. If blank ('') then no plot is made, else enter something like 'output_figure.pdf'\n",
    "\n",
    "OUTPUTS:\n",
    "data_x               --> The output time-stamps (will be the indicees of accepted points if no input provided).\n",
    "\n",
    "data_y               --> The y-axis of accepted points in the time-series.\n",
    "\n",
    "idx_out              --> The indicees of rejected points of the input time-series (data_y_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outrej(data_y_in,data_x_in=[],sd_check=4,fname='running median',filter_size = 5,max_iteration = 10,\n",
    "           diagnostic_figure='',comments=1,spread_function = 'rms'):\n",
    "\n",
    "\n",
    " def func1(x,p0,p1):\n",
    "  return(p0+x*p1)\n",
    " def func2(x,p0,p1,p2):\n",
    "  return(p0+p1*x+p2*x**2)\n",
    " \n",
    " def movingaverage (x,y, window):\n",
    "  weights = np.repeat(1.0, window)/window\n",
    "  sma = np.convolve(y, weights, 'valid')\n",
    "  sma_x = x[:]\n",
    "  sma_y = np.concatenate((np.ones(window-1)*sma[0],sma))\n",
    "  return(sma_x,sma_y)\n",
    " \n",
    " \n",
    " #if time values not provided, assume even sampling.\n",
    " if (type(data_x_in) == np.ndarray):\n",
    "  data_x = np.array(data_x_in)\n",
    " else:\n",
    "  ndat   = np.shape(data_y_in)[0]\n",
    "  data_x = np.arange(ndat)\n",
    " data_x_in_plot = np.array(data_x)   \n",
    "\n",
    " data_y = np.array(data_y_in)\n",
    " out_x = []\n",
    " out_y = []\n",
    " idx_out = []\n",
    "    \n",
    " #perform the iterations until max_iteration or no further rejections made   \n",
    " for iteration in range(max_iteration):\n",
    "  \n",
    "  #fit smooth function (linear, polynomial, running mean, running median, global median or global mean)\n",
    "  if (fname == 'linear'): \n",
    "   popt, pcov = mcf.curve_fit(func1, data_x, data_y)\n",
    "   model_y = popt[0] + data_x*popt[1]\n",
    "   model_x = np.array(data_x)\n",
    "  elif (fname == 'quadratic'):\n",
    "   popt, pcov = mcf.curve_fit(func2, data_x, data_y)\n",
    "   model_y = popt[0] + popt[1]*data_x + popt[2]*data_x**2\n",
    "   model_x = np.array(data_x) \n",
    "  elif (fname == 'running median'):\n",
    "   model_y = ssig.medfilt(data_y, kernel_size=filter_size)\n",
    "   model_x = np.array(data_x)\n",
    "  elif (fname == 'global median'):\n",
    "   a =  np.median(data_y)\n",
    "   ndy = np.shape(data_y)[0]\n",
    "   model_y = a*np.ones(ndy)\n",
    "   model_x = np.array(data_x)\n",
    "  elif (fname == 'running mean'):\n",
    "   model_x,model_y = movingaverage(data_x,data_y,filter_size)\n",
    "  elif (fname == 'global mean'):\n",
    "   a =  np.mean(data_y)\n",
    "   ndy = np.shape(data_y)[0]\n",
    "   model_y = a*np.ones(ndy)\n",
    "   model_x = np.array(data_x)\n",
    " \n",
    "  #compute the residuals ( abs[data-model])\n",
    "  #model_itp = np.interpolate(data_x,model_x,model_y)   \n",
    "  residual = data_y - model_y\n",
    " \n",
    "     \n",
    "  #identify points greater than sd_outlier from the model \n",
    "  if (spread_function == 'rms'):\n",
    "   sd = np.std(residual)\n",
    "  elif (spread_function == 'mad'):\n",
    "   sd = robust.mad(residual)\n",
    "  else:\n",
    "   raise ValueError('Please ensure that the \"spread_function\" argument is set to \"rms\" or \"mad\"')\n",
    "  \n",
    "  id_out = np.where(np.abs(residual) > sd_check*sd)[0]\n",
    "  n_out = np.shape(id_out)[0] \n",
    " \n",
    "     \n",
    "  #flag outliers and remove from them from the data arrays for the next iteration\n",
    "  #for id in id_out:\n",
    "  # print data_x[id],data_y[id]\n",
    " \n",
    "  out_x.append(data_x[id_out])\n",
    "  out_y.append(data_y[id_out])\n",
    "  data_x = np.delete(data_x,id_out)\n",
    "  data_y = np.delete(data_y,id_out)\n",
    " \n",
    "  #save a record of rejected array indicees \n",
    "  idx_out.append(id_out)\n",
    "\n",
    "  #exit the loop prematurely if no outliers found\n",
    "  if (np.shape(id_out)[0] == 0):\n",
    "   if (comments == 1):\n",
    "    print 'no further oultiers found after iteration ',iteration,' exiting...'\n",
    "   break\n",
    "  else:\n",
    "   if (comments == 1):\n",
    "    print 'iteration ',iteration,'\\n ',n_out,'outliers found'\n",
    "    \n",
    " #flag a warning if the outlier rejection has not converged after max_iteration iterations\n",
    " if ((iteration == max_iteration - 1) and (comments == 1)):\n",
    "  print 'warning: Outlier rejection did not converge after a maximum,', max_iteration,\\\n",
    " ' iterations re-run for more iterations or check input data for bugs'\n",
    " \n",
    "    \n",
    "    \n",
    " idx_out = np.array(np.concatenate(idx_out) ,dtype='int')  \n",
    " #plot a diagnostic plot if requested\n",
    " if (diagnostic_figure != ''):\n",
    "  \n",
    "  gs1 = gridspec.GridSpec(4, 5)\n",
    "  gs1.update(left=0.1, right=0.9, bottom=0.1,top = 0.9, wspace=0.05,hspace = 0.0)\n",
    "  ax1 = plt.subplot(gs1[:3, :4])\n",
    "  ax1.plot(data_x,data_y,label='Time series',color='k')\n",
    "  ax1.plot(model_x,model_y,label='Smooth model',color='blue')\n",
    "  ax1.scatter(data_x_in_plot[idx_out],data_y_in[idx_out],marker='o',color='red',label='Outliers')\n",
    "  plt.legend()\n",
    "  ax1.set_xlabel('Time')\n",
    "  ax1.set_ylabel('Time-series values')\n",
    "  \n",
    "  axres = plt.subplot(gs1[3:, :4])\n",
    "  axres.plot(model_x,residual)\n",
    "  axres.set_xlabel('Time')\n",
    "  xl = list(axres.get_xlim())\n",
    "  axres.set_xlim(xl)\n",
    "  ax1.set_xlim(xl)\n",
    "  axres.plot(xl,[0,0],ls=':')\n",
    "  axres.set_ylabel('residuals \\n (data - model)') \n",
    "\n",
    "  axhist = plt.subplot(gs1[:3, 4])\n",
    "  axhist.hist(data_y,orientation='horizontal',color='k',histtype='step')\n",
    "  axhist.set_xticklabels([])\n",
    "  axhist.set_yticklabels([])\n",
    "  xy = list(ax1.get_ylim())\n",
    "  axhist.set_ylim(xy)\n",
    "\n",
    "  if (diagnostic_figure == 'show'):\n",
    "   plt.show()\n",
    "  else:\n",
    "   plt.savefig(diagnostic_figure)\n",
    "  plt.clf()\n",
    "    \n",
    " return(data_y,data_x,model_y,idx_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set 'demo_single_timeseries = 1' for a demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_single_timeseries = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (demo_single_timeseries == 1):\n",
    " #generate some fake random data to test the code. Specify the parameters of the fake data below\n",
    " filter_size = 5\n",
    " fname = 'running median'\n",
    " sd_fake = 3.0\n",
    " n_fake  = 1000\n",
    " \n",
    " #some subset of the fake data will be the 'test outliers' the code is tasked to identify.\n",
    " #the parameters should be setup so that n_outlier < n_fake and sd_outlier > sd_fake.\n",
    " n_outlier = 23\n",
    " sd_outlier = 10.0\n",
    " \n",
    " data_y = np.random.randn(n_fake)*sd_fake\n",
    " id_test = np.random.choice(np.arange(n_fake), size=n_outlier, replace=False)\n",
    " data_y[id_test] = np.random.randn(n_outlier)*sd_outlier\n",
    " \n",
    " #also have the option of including irregularly spaced time-series data by speciffying a \n",
    " #unique input array for the x-axis (code assumes regular sampling if no input)\n",
    " data_x = np.arange(n_fake)\n",
    " \n",
    " #Call the outlier rejection function defined above and test on the fake data.\n",
    " data_y_pass,data_x_pass,model_y,idx_outlier = outrej(data_y,data_x,sd_check=3.5,\n",
    " fname='running median',filter_size = 5,max_iteration=10,diagnostic_figure='show')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above is appropriate for identifying outliers from a single time series. With a few adaptions the function can allow for multiple time-series input.\n",
    "\n",
    "The function below is apporpriate for cross-checking simultaneous epochs in adjacent time-series data using the sigma-clip routine in parallel epoch-by-epoch. This is useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now define the parallel outlier rejection sigma clip\n",
    "def outrej_parallel(data_y,sd_check=5,fname='running median',filter_size = 5,max_iteration=10,diagnostic_figure='',\n",
    "                    spread_function = 'rms'):\n",
    " \n",
    "\n",
    "\n",
    " n_epoch,n_timeseries = np.shape(data_y)\n",
    "\n",
    " #now compute the sigma-clip routine across parallel time series one time at a time\n",
    " id_outliers = np.zeros((2,0),dtype='int')\n",
    " for i in range(n_epoch):\n",
    "  y_now = data_y[i,:]\n",
    "  y_pass,x_pass,model,idx_outlier = outrej(y_now,sd_check=sd_check,fname=fname,\n",
    "  filter_size = filter_size,max_iteration=max_iteration,diagnostic_figure='',\n",
    "  comments=0,spread_function = spread_function)\n",
    "  \n",
    "  #save the points identified as outliers in a 2d array with 0th column corresponding to\n",
    "  #time series ID and 1st column to the epoch id\n",
    "  n_outliers = np.shape(idx_outlier)\n",
    "  id_out = np.vstack( (np.ones(n_outliers,dtype='int')*i,idx_outlier) )\n",
    "  id_outliers = np.hstack((id_outliers,id_out))\n",
    " id_outliers = id_outliers.T[:,[1,0]]\n",
    " \n",
    " \n",
    " #plot the results\n",
    " gs1 = gridspec.GridSpec(4, 4)\n",
    " gs1.update(left=0.1, right=0.9, bottom=0.1,top = 0.9, wspace=0.05,hspace = 0.0)\n",
    " ax1 = plt.subplot(gs1[:, :])\n",
    " for i in range(n_timeseries):\n",
    "  if (i == 0):\n",
    "   labts = 'Time series'\n",
    "   labo  = 'Outliers'\n",
    "  else:\n",
    "   labts = None\n",
    "   labo  = None\n",
    "  ax1.plot(data_y[:,i],label=labts,color='k')\n",
    "  id_ts = np.where(id_outliers[:,0] == i)[0]\n",
    "  ax1.scatter(id_outliers[id_ts,1],data_y[id_outliers[id_ts,1],id_outliers[id_ts,0]],color='r',label=labo)\n",
    " plt.legend()\n",
    " ax1.set_title(np.str(n_timeseries)+' timeseries, ' + np.str(n_epoch) + ' epochs per series')\n",
    " ax1.set_xlabel('Time')\n",
    " ax1.set_ylabel('Time-series values')\n",
    " \n",
    " if (diagnostic_figure == 'show'):\n",
    "  plt.show()\n",
    " else:\n",
    "  plt.savefig(diagnostic_figure)\n",
    "  \n",
    "  \n",
    "  \n",
    " return(id_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The demonstration below generates 'n_timeseries' sets of timeseries data, each with 'n_epoch' points. Anomalous variability is introduced in 'id_outlier' timeseries to simulate rogue outlying points. And the 'outrej_parallel' routine is asked to identify these.\n",
    "\n",
    "Set 'demo_multi_timeseries = 1' for a demonstration of the parallel sigma clip routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_multi_timeseries = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (demo_multi_timeseries == 1):\n",
    " sd_background = 3.0\n",
    " n_epoch  = 1000\n",
    " n_timeseries = 100\n",
    " id_outlier = 23\n",
    " time_anomaly = 350\n",
    " grad_anomaly = 0.1\n",
    " diagnostic_figure = 'show'\n",
    " \n",
    " \n",
    " \n",
    " data_y = np.reshape( np.random.randn(n_epoch * n_timeseries), (n_epoch,n_timeseries) )\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " #introduce a linear gradient into one timeseries to simulate non-stationarity\n",
    " data_y[time_anomaly:,id_outlier] += data_y[time_anomaly,id_outlier] + np.arange(0,n_epoch-time_anomaly,1)*grad_anomaly\n",
    " \n",
    " \n",
    " #test the parallel outlier rejection routine here\n",
    " op = outrej_parallel(data_y,sd_check=5,fname='running median',filter_size = 5,max_iteration=10,\n",
    "                      diagnostic_figure='show',spread_function = 'rms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final function to perform the outrej formulation in series rather than parallel. This is the same as the first function 'outrej' but accepts simultaneous multi light curve input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now define the parallel outlier rejection sigma clip\n",
    "def outrej_series(data_y,sd_check=5,fname='running median',filter_size = 5,max_iteration=10,diagnostic_figure='',\n",
    "                 spread_function = 'rms'):\n",
    " \n",
    "\n",
    "\n",
    " n_epoch,n_timeseries = np.shape(data_y)\n",
    "\n",
    " #now compute the sigma-clip routine across each time series one time at a time\n",
    " id_outliers = np.zeros((2,0),dtype='int')\n",
    " modelsave = []\n",
    " for i in range(n_timeseries):\n",
    "  y_now = data_y[:,i]\n",
    "  y_pass,x_pass,model,idx_outlier = outrej(y_now,sd_check=sd_check,fname=fname,\n",
    "  filter_size = filter_size,max_iteration=max_iteration,diagnostic_figure='',\n",
    "  comments=0,spread_function = spread_function)\n",
    "  \n",
    "  #save the smooth model\n",
    "  modelsave.append(model)\n",
    "  #save the points identified as outliers in a 2d array with 0th column corresponding to\n",
    "  #time series ID and 1st column to the epoch id\n",
    "  n_outliers = np.shape(idx_outlier)\n",
    "  id_out = np.vstack( (np.ones(n_outliers,dtype='int')*i,idx_outlier) )\n",
    "  id_outliers = np.hstack((id_outliers,id_out))\n",
    " id_outliers = id_outliers.T[:,[1,0]]\n",
    " \n",
    " \n",
    " #plot the results\n",
    " gs1 = gridspec.GridSpec(4, 4)\n",
    " gs1.update(left=0.1, right=0.9, bottom=0.1,top = 0.9, wspace=0.05,hspace = 0.0)\n",
    " ax1 = plt.subplot(gs1[:, :])\n",
    " for i in range(n_timeseries):\n",
    "  if (i == 0):\n",
    "   labts = 'Time series'\n",
    "   labo  = 'Outliers'\n",
    "   labmod = 'Smooth model'\n",
    "  else:\n",
    "   labts = None\n",
    "   labo  = None\n",
    "   labmod = None\n",
    "  ax1.plot(data_y[:,i],label=labts,color='k')\n",
    "  ax1.plot(modelsave[i],color='b',label=labmod)\n",
    "  id_ts = np.where(id_outliers[:,0] == i)[0]\n",
    "  ax1.scatter(id_outliers[id_ts,1],data_y[id_outliers[id_ts,1],id_outliers[id_ts,0]],color='r',label=labo)\n",
    " plt.legend()\n",
    " ax1.set_title(np.str(n_timeseries)+' timeseries, ' + np.str(n_epoch) + ' epochs per series')\n",
    " ax1.set_xlabel('Time')\n",
    " ax1.set_ylabel('Time-series values')\n",
    " \n",
    " if (diagnostic_figure == 'show'):\n",
    "  plt.show()\n",
    " else:\n",
    "  plt.savefig(diagnostic_figure)\n",
    "  \n",
    "  \n",
    "  \n",
    " return(id_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a function to tie everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_smooth(data_y,sd_check=5,fname='running median',runtype='series',filter_size = 5,\n",
    "                   max_iteration=10,diagnostic_figure='',spread_function = 'rms'):\n",
    "\n",
    " if (runtype=='parallel'):\n",
    "  if (type(data_y)==np.ndarray):\n",
    "   if (len(np.shape(data_y)) !=2):\n",
    "    raise ValueError('For parallel outlier detection, \\\n",
    "    data_y must be a 2D numpy array with epochs as the first axis and \\\n",
    "    different light curves as the second')\n",
    "  id_outliers = outrej_parallel(data_y,sd_check=sd_check,fname=fname,filter_size = filter_size,\n",
    "                                max_iteration=max_iteration,diagnostic_figure=diagnostic_figure,\n",
    "                               spread_function = spread_function)\n",
    "\n",
    " elif (runtype == 'series'):\n",
    "  if (len(np.shape(data_y)) ==1):\n",
    "    a,b,c,id_outliers = outrej(data_y,sd_check=sd_check,fname=fname,\n",
    "                               filter_size = filter_size,max_iteration = max_iteration,\n",
    "                               diagnostic_figure=diagnostic_figure,comments=0,spread_function = spread_function)\n",
    "  else:\n",
    "   id_outliers = outrej_series(data_y,sd_check=sd_check,fname=fname,filter_size = filter_size,\n",
    "                               max_iteration=max_iteration,diagnostic_figure=diagnostic_figure,\n",
    "                              spread_function = spread_function) \n",
    "\n",
    " else:\n",
    "  raise ValueError('Please ensure that the \"runtype\" argument is specified as either parallel or series and \\\\\n",
    "  that the input data is in the form of either \\n \\\n",
    "  1) A 1D numpy array for a single timeseries with epochs along the axis. or \\n \\\n",
    "  2) A 2D numpy array for a data cube of multiple time series with epochs as the first axis and \\\n",
    "     different time series as the second.')\n",
    " \n",
    " return(id_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
