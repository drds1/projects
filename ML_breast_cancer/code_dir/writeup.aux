\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Breast Cancer Machine Learning Study}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Source}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}K-nearest neighbour algorithm and classification}{1}{section.3}}
\newlabel{eq_euclid}{{1}{2}{K-nearest neighbour algorithm and classification}{equation.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Hidden-Layer Neural Network}{2}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Theory}{2}{subsection.4.1}}
\newlabel{eq_sigmoid}{{2}{2}{Theory}{equation.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example neural network with a single neuron. The network has three inputs to neuron $j$ denoted by $X_{ij}$ with weights $W_{ij}$. The output from the neuron is given by $a_j$ where the activation function $f(z)$ is given in Equation \ref  {eq_sigmoid}.\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig_temp}{{1}{3}{Example neural network with a single neuron. The network has three inputs to neuron $j$ denoted by $X_{ij}$ with weights $W_{ij}$. The output from the neuron is given by $a_j$ where the activation function $f(z)$ is given in Equation \ref {eq_sigmoid}.\relax }{figure.caption.1}{}}
\newlabel{eq_sigmoid}{{3}{3}{Theory}{equation.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}optimizing the weights}{3}{subsection.4.2}}
\newlabel{eq_cost}{{4}{3}{optimizing the weights}{equation.4.4}{}}
\newlabel{eq_adjust_w}{{5}{4}{optimizing the weights}{equation.4.5}{}}
\newlabel{eq_partial_tot}{{6}{4}{optimizing the weights}{equation.4.6}{}}
\newlabel{eq_partdiv}{{7}{4}{optimizing the weights}{equation.4.7}{}}
\newlabel{eq_delta}{{8}{4}{optimizing the weights}{equation.4.8}{}}
\newlabel{eq_delta_in}{{9}{4}{optimizing the weights}{equation.4.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Dimensionality Reduction Using PCA}{4}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{5}{section.6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Percentage of correctly-classified samples in the test data vs the number of samples in the training data. The colours indicate whether a K-nearest-neighbour method or neural network approach was used to classify the dataset, and whether PCA was first used to collapse the 4D data space to a 2D dataspace.\relax }}{6}{figure.caption.2}}
\newlabel{fig_accuracy}{{2}{6}{Percentage of correctly-classified samples in the test data vs the number of samples in the training data. The colours indicate whether a K-nearest-neighbour method or neural network approach was used to classify the dataset, and whether PCA was first used to collapse the 4D data space to a 2D dataspace.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{6}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Computation time (in seconds) as a functino of number of samples in the training data. The colours indicate whether a K-nearest-neighbour method or neural network approach was used to classify the dataset, and whether PCA was first used to collapse the 4D data space to a 2D dataspace.\relax }}{7}{figure.caption.3}}
\newlabel{fig_time}{{3}{7}{Computation time (in seconds) as a functino of number of samples in the training data. The colours indicate whether a K-nearest-neighbour method or neural network approach was used to classify the dataset, and whether PCA was first used to collapse the 4D data space to a 2D dataspace.\relax }{figure.caption.3}{}}
